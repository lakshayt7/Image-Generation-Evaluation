Downloading: "https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth" to /gpfs/home/lt2504/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth
  0%|          | 0.00/91.2M [00:00<?, ?B/s]  9%|▉         | 8.33M/91.2M [00:00<00:00, 87.1MB/s] 18%|█▊        | 16.6M/91.2M [00:00<00:01, 63.9MB/s] 25%|██▌       | 23.1M/91.2M [00:00<00:01, 54.5MB/s] 31%|███▏      | 28.5M/91.2M [00:00<00:01, 46.6MB/s] 36%|███▋      | 33.2M/91.2M [00:00<00:01, 41.9MB/s] 41%|████      | 37.3M/91.2M [00:00<00:01, 41.4MB/s] 45%|████▌     | 41.3M/91.2M [00:00<00:01, 40.5MB/s] 50%|████▉     | 45.2M/91.2M [00:01<00:01, 36.7MB/s] 53%|█████▎    | 48.7M/91.2M [00:01<00:01, 35.1MB/s] 57%|█████▋    | 52.3M/91.2M [00:01<00:01, 35.6MB/s] 61%|██████▏   | 55.9M/91.2M [00:01<00:01, 36.2MB/s] 65%|██████▌   | 59.4M/91.2M [00:01<00:00, 35.3MB/s] 69%|██████▉   | 63.1M/91.2M [00:01<00:00, 36.3MB/s] 74%|███████▎  | 67.1M/91.2M [00:01<00:00, 37.9MB/s] 78%|███████▊  | 70.8M/91.2M [00:01<00:00, 36.3MB/s] 81%|████████▏ | 74.3M/91.2M [00:02<00:00, 26.5MB/s] 85%|████████▍ | 77.2M/91.2M [00:02<00:00, 24.6MB/s] 87%|████████▋ | 79.8M/91.2M [00:02<00:00, 25.3MB/s] 90%|█████████ | 82.4M/91.2M [00:02<00:00, 25.1MB/s] 93%|█████████▎| 85.1M/91.2M [00:02<00:00, 25.9MB/s] 96%|█████████▌| 87.7M/91.2M [00:02<00:00, 25.7MB/s] 99%|█████████▉| 90.3M/91.2M [00:02<00:00, 26.1MB/s]100%|██████████| 91.2M/91.2M [00:02<00:00, 34.6MB/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:05<00:00,  5.44s/it]100%|██████████| 1/1 [00:05<00:00,  5.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:01<00:00,  1.69s/it]100%|██████████| 1/1 [00:01<00:00,  1.74s/it]
Traceback (most recent call last):
  File "src/main.py", line 37, in <module>
    img_score, txt_score = clip_evaluator.evaluate(image_path, gt_path, text_prompt)
  File "/gpfs/home/lt2504/dreambooth/Image-Generation-Evaluation/src/clip_score.py", line 65, in evaluate
    sim_samples_to_img  = self.img_to_img_similarity(src_images, gen_samples)
  File "/gpfs/home/lt2504/dreambooth/Image-Generation-Evaluation/src/clip_score.py", line 46, in img_to_img_similarity
    src_img_features = self.get_image_features(src_images)
  File "/gpfs/home/lt2504/dreambooth/Image-Generation-Evaluation/src/clip_score.py", line 38, in get_image_features
    image_features = self.encode_images(img)
  File "/gpfs/scratch/lt2504/image-eval/imagen/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home/lt2504/dreambooth/Image-Generation-Evaluation/src/clip_score.py", line 23, in encode_images
    images = self.preprocess(images).to(self.device)
  File "/gpfs/scratch/lt2504/image-eval/imagen/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/gpfs/scratch/lt2504/image-eval/imagen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/scratch/lt2504/image-eval/imagen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/scratch/lt2504/image-eval/imagen/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "/gpfs/scratch/lt2504/image-eval/imagen/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 361, in normalize
    raise TypeError(f"img should be Tensor Image. Got {type(tensor)}")
TypeError: img should be Tensor Image. Got <class 'str'>
